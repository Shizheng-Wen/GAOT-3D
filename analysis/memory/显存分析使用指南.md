# GAOT-3D 显存分析工具使用指南

## 概述

本文档提供了两个专门用于分析GAOT-3D模型显存使用情况的脚本，帮助您理解**edges数量**对显存占用峰值的影响。

## 🎯 分析目标

根据您的描述，显存峰值主要由**encoder和decoder导致**，特别是在**IntegralTransform**中：
- 每条edge的信息需要过MLP处理
- edges数量直接影响显存开销
- 需要量化这种关系以优化模型设计

## 📋 脚本概览

### 1. `memory_analysis_script.py` - 全面分析脚本
**特点：**
- 🔍 测试完整的GAOT-3D组件（Encoder, Decoder, 完整模型）
- 📊 对比训练vs推理模式的显存差异
- 🎯 系统性测试不同edges规模的影响
- 📈 生成详细的可视化分析报告

**适用场景：**
- 初次分析，需要全面了解各组件显存使用
- 对比不同组件的显存开销
- 需要完整的实验报告

### 2. `edge_memory_profiler.py` - 核心瓶颈分析脚本  
**特点：**
- 🎯 专门测试IntegralTransform的MLP处理瓶颈
- ⚡ 更快速，专注于核心问题
- 🧠 测试不同MLP配置的影响
- 📉 提供理论vs实际显存对比

**适用场景：**
- 已知瓶颈在IntegralTransform，需要深入分析
- 优化MLP配置
- 快速测试特定配置

## 🚀 使用方法

### 环境准备
```bash
# 确保在GAOT-3D项目根目录
cd /path/to/GAOT-3D

# 确保有GPU和必要的包
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### 运行全面分析
```bash
# 运行完整分析（推荐首次使用）
python memory_analysis_script.py
```

**预期输出：**
- 📊 实时显存监控信息
- 💾 各组件在不同edges下的显存使用
- 📈 可视化图表 (`memory_analysis_results.png`)
- 💽 原始数据 (`memory_analysis_data.csv`)

### 运行核心瓶颈分析
```bash
# 运行IntegralTransform专项分析
python edge_memory_profiler.py
```

**预期输出：**
- 🔍 不同MLP配置的显存测试
- 📊 边数量缩放分析
- 📈 理论vs实际对比图 (`edge_memory_analysis.png`)
- 💽 详细数据 (`edge_memory_results.csv`)

## ⚙️ 配置参数

### 全面分析脚本配置
在`memory_analysis_script.py`的`main()`函数中修改：

```python
config = MemoryTestConfig(
    device="cuda:0",              # GPU设备
    num_physical_nodes=5000,      # 物理节点数
    num_latent_tokens=4096,       # 潜在tokens数
    min_edges=5000,               # 最小edges数
    max_edges=500000,             # 最大edges数 ⚠️根据GPU调整
    num_test_points=12,           # 测试点数量
    test_encoder=True,            # 是否测试encoder
    test_decoder=True,            # 是否测试decoder
    test_full_model=False,        # 是否测试完整模型（慢）
    test_training_mode=True,      # 是否测试训练模式
    test_inference_mode=True      # 是否测试推理模式
)
```

### 核心分析脚本配置
在`edge_memory_profiler.py`的`main()`函数中修改：

```python
# 测试的edges数量范围
edge_counts = [
    5000, 10000, 20000, 50000, 
    100000, 200000, 500000, 1000000  # ⚠️根据GPU调整
]

# MLP配置
mlp_configs = [
    [64, 64],           # 轻量级
    [128, 128, 128],    # 标准（你的当前配置）
    [256, 256, 256],    # 重量级
]
```

## 📊 结果解读

### 关键指标
1. **峰值显存 (Peak Memory)**: 最大显存占用
2. **显存增长率 (Scaling Factor)**: 随edges增长的显存缩放因子
3. **训练/推理比例**: 训练模式相对推理模式的显存倍数
4. **理论vs实际**: 理论计算的edge特征显存 vs 实际峰值显存

### 期望结果
- **线性关系**: 显存使用应与edges数量呈线性或接近线性关系
- **缩放因子**: 理想情况下接近1.0（完全线性）
- **训练开销**: 训练模式通常是推理模式的1.5-3倍显存

### 优化建议指标
基于结果，您可以：

1. **edges数量过多时:**
   - 使用更小的MLP配置
   - 实施edge sampling策略
   - 考虑梯度检查点(gradient checkpointing)

2. **MLP配置过大时:**
   - 减少MLP层数或隐藏单元数
   - 使用不同的transform_type

3. **训练显存过大时:**
   - 使用混合精度训练
   - 减小batch size
   - 启用梯度累积

## ⚠️ 注意事项

### GPU显存限制
- **小GPU (4-8GB)**: 建议max_edges ≤ 100K
- **中GPU (12-16GB)**: 建议max_edges ≤ 500K  
- **大GPU (24GB+)**: 可以测试max_edges ≥ 1M

### 脚本运行时间
- **全面分析**: 10-30分钟（取决于测试点数量）
- **核心分析**: 5-15分钟

### 错误处理
- **OOM错误**: 脚本会自动捕获并跳过更大的测试
- **导入错误**: 确保在项目根目录运行
- **CUDA错误**: 检查GPU驱动和PyTorch安装

## 🔧 高级用法

### 自定义测试场景
您可以修改脚本来测试特定场景：

```python
# 只测试特定的edges数量
edge_counts = [50000, 100000, 200000]

# 只测试推理模式
modes = ['inference']

# 测试特定的MLP配置
mlp_configs = [[128, 128, 128]]  # 你的当前配置
```

### 批量分析
如果需要测试多种配置，可以编写循环：

```python
for coord_dim in [2, 3]:
    for feature_dim in [32, 64, 128]:
        # 运行测试...
```

## 📈 实用示例

假设您发现在50万edges时发生OOM，您可以：

1. **确定瓶颈**: 运行核心分析确定是MLP配置问题
2. **优化配置**: 测试更小的MLP配置 `[64, 64]`
3. **验证改进**: 重新测试看是否能处理更多edges
4. **平衡性能**: 在显存使用和模型性能间找平衡

## 🎉 总结

这两个脚本将帮助您：
- 🔍 **量化edges对显存的影响**
- 📊 **识别显存瓶颈组件**
- ⚙️ **优化MLP配置**
- 📈 **制定显存管理策略**

开始使用时建议先运行`edge_memory_profiler.py`快速了解核心瓶颈，然后使用`memory_analysis_script.py`进行全面分析。 